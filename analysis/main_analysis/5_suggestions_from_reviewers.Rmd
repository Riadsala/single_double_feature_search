---
title: "Supplementary Materials: Suggestions from Reviewers"
author: "Alasdair D.F. Clarke and Anna E. Hughes"
date: "2023-03-24"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.height = 3,
  fig.align = "center")
```

# Introduction

```{r load-packages, include = FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
library(ggpmisc)
library(ggridges)
library(corrr)
library(knitr)
library(kableExtra)
```

Here we present two additional analyses that were suggested during the Stage Two peer review process. We thank the reviewers for their suggestions. 


```{r}
# set ggplot2 theme
theme_set(ggthemes::theme_tufte())
colourPalette <- c("#e78429", "#ed968c", "#7c4b73","#aadce0", "#72bcd5", "528fad")

# use parallel cores for mcmc chains!
options(mc.cores = 4)

# reduce the number of decimal places
options(digits = 3)

# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")

# set seed to make sure everything is reproducible 
set.seed(100320021)
```


# Effect of block on correlations

In `4_Planned_Explorations` we reported that there were correlations *within* feature classes: for example, for $D_c$, pink correlates well with orange and purple, but not with shape features (i.e. diamond, triangle and circle).

During peer review it was suggested that we could partially disentangle contributions of feature type and block from one another by looking at how the correlations change within sub-blocks. 

One challenge with this approach is that our experiment featured a block design: shape-only trials were always presented in one block only (at a random position within the experiment). Colour-only trials were then spread across the four other blocks of the experiment. We suggest that the lack of correlation between colour and feature might be because there are block effects: knowing the search slope for a feature in the first block allows us to predict the search slopes of the other features in that block, but tells us nothing of the observer's behaviour in the second block. 

To test this, we can look (for the colour-only trials) whether the correlations vary between block. If the correlation results are primarily being driven by block, then we could expect to see a decrease in the correlation over sub-blocks i.e. there are high correlations within a block, that then decrease (perhaps increasingly so as you move further away from e.g. block one). If this is not the case, it would suggest that block *per se* is not having a strong effect on the correlations, perhaps suggesting there is a real feature based effect. Of course, a stronger test of this would be to change the design of the experiment so that all trials are randomly interleaved, or all blocked.

## Fitting the model

We're going to refit the model (single colour feature only), this time including block info. 

```{r cache=TRUE, warning = FALSE}
## Import and Remove Outliers 
source("1_pre_process_data.R")

# remove feature = circle, diamond, triangle (these are all expt 1b, which is blocked)
# expt 1b is in a different block for each person so each person will have one block missing at random.
d1 <- d1 %>% 
  mutate(block = as_factor(block)) %>%
  filter(feature == "pink" | feature == "purple" | feature == "orange")
```

The code below does not run by default (as it is slow). Please set 'eval = TRUE' in the below code snippet if you would like to run the block model.

```{r, eval = FALSE}

n_chains = 4
n_itr = 5000

fit_model <- function(d, fam, prior, formula, samp_prior = "no") { 
   
   # wrapper function for running models
   # this way, easier to make sure all models are using the same settings!
   
   m <- brm(
     formula,
     data = d,
     family = brmsfamily(fam),
     prior = prior,
     chains = n_chains,
     iter = n_itr,
     init = my_inits,
     save_pars = save_pars(all=TRUE),
     silent = TRUE,
     backend = 'cmdstanr',
     control = list(adapt_delta = 0.9),
     sample_prior = samp_prior)
   
   return(m)
}
 
 
my_f <- brms::bf(rt ~ 0 + block + block:feature:lnd + (0 + block + feature:lnd|observer),
                  ndt ~ 1 + (1|observer))
 
my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))
 
my_prior <- c(
  # prior_string("normal(-0.5, 0.3)", class = "Intercept"),
   prior_string("normal(0, 0.2)", class = "b"),
   prior_string("normal(-1, 0.2)", class = "b", coef = "block1"),
   prior_string("normal(-1, 0.2)", class = "b", coef = "block2"),
   prior_string("normal(-1, 0.2)", class = "b", coef = "block3"),
   prior_string("normal(-1, 0.2)", class = "b", coef = "block4"),
   prior_string("normal(-1, 0.2)", class = "b", coef = "block5"),
   prior_string("normal(-1, 0.5)", class = "Intercept", dpar = "ndt" ),
   prior_string("cauchy(0, 0.4)", class = "sigma"),
   prior_string("cauchy(0, 0.05)", class = "sd"),
   prior_string("cauchy(0, 0.05)", class = "sd", dpar = "ndt"))
 
# now run model for single feature data
m <- fit_model(d1, "shifted_lognormal", my_prior, my_f)
saveRDS(m, "exp1_block.model")
rm(m)

```

The code snippet below assumes that you have either run the model yourself (see code chunk above) or downloaded our pre-run models.

```{r}

# read in model
m <- readRDS("exp1_block.model")

```

We must first extract the slopes per person x feature x block.

```{r}
# extract the slopes per person per feature per block
samples <- gather_draws(m, `[rb]_.*`, regex=T, ndraws = 100)

samples_ff <- samples %>%
  filter(str_detect(.variable, "b_")) %>%
  filter(str_detect(.variable, ":lnd")) %>%
  separate(.variable, c("block", "feature", "lnd"),  ":") %>%
  select(-lnd, -.chain, -.iteration) %>%
  mutate(block = str_remove(block, "b_"),
         feature = str_remove(feature, "feature")) %>%
  rename(D = ".value")

samples_rf <- filter(samples, str_detect(.variable, "r_")) %>% 
  select(-.chain, -.iteration) %>% 
  filter(str_detect(.variable, ":lnd")) %>%
  rename(feature = ".variable", rD = ".value") %>%
  separate(feature, into = c("observer", "feature"), ",") %>%
  mutate(observer = parse_number(observer),
         feature = str_remove(feature, "feature"),
         feature = str_remove(feature, ":lnd"),
         feature = str_remove(feature, "]")) %>%
  separate(feature, c("block", "feature"), ":") 

full_join(samples_ff, samples_rf) %>%
      mutate(D = D + rD) %>%
      select(-rD) -> samples
```

## Computer correlation per sample

First we define a little function to calculate correlations within feature from one block to the next:

```{r}

get_cor_matrix <- function(df, key) {
  
  df %>% 
    select(-observer) %>%
    correlate() %>%
    mutate(.draw = key$.draw)-> dout
  
  return(dout)
}
```

Now for each feature x block x sample, we compute the correlations.

```{r, message = FALSE}

samples %>% 
  unite(block_feature, block, feature) %>%
  pivot_wider(names_from = block_feature, values_from = D) %>%
  group_by(.draw) %>%
  group_map(get_cor_matrix) %>%
  bind_rows -> dc
```

We then make a plot.

```{r, warning = FALSE}
dc %>% 
  rename(block_feature1 = "term") %>%
  pivot_longer(-c(.draw, block_feature1), names_to = "block_feature2", values_to = "r") %>%
  separate(block_feature1, into = c("blockA", "featureA")) %>%
  separate(block_feature2, into = c("blockB", "featureB")) %>%
  mutate(blockA = parse_number(blockA),
         blockB = parse_number(blockB)) %>%
  select(.draw, blockA, featureA, blockB, featureB, r) -> dc


dc %>%
  filter(blockA == 1) %>%
  group_by(featureA, featureB, blockB) %>%
  median_hdci(r, .width = c(.53, .97)) %>%
  rename(feature = "featureA") %>%
  ggplot(aes(blockB, ymin = .lower, y = r, ymax = .upper, 
             group = interaction( .width))) + 
  geom_path() + 
  geom_hline(yintercept = 0, linetype = 2) + 
  geom_ribbon(alpha = 0.125) + 
  facet_grid(feature~featureB)  +
  scale_x_continuous("block") +
  scale_y_continuous("correlation (r) with block 1")
```

These results suggest that there remains a fairly high correlation across blocks: for example, in the top left plot, we can see that for orange-orange correlations, the correlation ($r$) with block 1 remains fairly steady at around $r = 0.5$. This remains true even across different colours (e.g. orange-purple), although perhaps the purple correlations are slightly weaker overall, with the 97% HDCI containing $r = 0$ at some points. We note that we have relatively little data for this type of analysis though, weakening our power. 

Overall, these post hoc results suggest that our results cannot simply be explained by the block structure of the experiment, and that we really do see better correlations for features of the same class, though we acknowledge that to test this hypothesis stringently we would need to design the experiment differently.

# Removing small/negative slopes

Both reviewers suggested that it would be interesting to check whether removing participants with small/negative search slopes would change the predictions of which model best fit the data.

To be as conservative as possible, we tested this by removing the purple and pink conditions entirely, as well as all data from the inner ring. We then remove all people with negative slopes.

## Setting up the data

First, we read in the data and models again: 
```{r}
source("../scripts/pred_rt_functions.R")
source("1_pre_process_data.R")

d1 %>% mutate(observer = as.numeric(observer)) %>%
  select(-nd) -> d1

d2 %>% mutate(observer = as.numeric(observer)) %>%
  select(-nd) -> d2

d2 %>% unite(feature, feature1, feature2) -> d2

m1 <- readRDS("exp1_ring.model") 

m2 <- readRDS("exp2_ring.model") 
```

Next, we extract the slopes.

```{r}
samples1 <- get_slopes(m1, rings = TRUE, fixed = FALSE)
```

We then check the probability that the slope is negative. We can see that most of people with negative slopes are in ring 1, and the pink and purple conditions.

```{r, message= FALSE}
samples1 %>% group_by(feature, ring, observer) %>%
  summarise(prob_neg = mean(D<0), .groups = "drop") %>%
  filter(prob_neg > 0.0) -> neg_slopes

neg_slopes %>% group_by(feature, ring) %>%
  summarise(n = n()) %>%
  knitr::kable()
```

Thus, we decided to remove the purple and pink conditions entirely, as well as the inner ring.

If we remove all people with a negative slope, we then have just three people to remove to avoid having any negative slopes. 

```{r}

neg_slopes %>% 
  filter(!(feature %in% c("pink", "purple")), ring>1) -> neg_slopes2

neg_slopes2
```

## Predicting reaction times

We now repeat the predictions for individuals (code copied from `4_planned_explorations`).


```{r}
ndraws <- 100

source("../scripts/pred_rt_functions.R")

model1 <- get_rt_model_ring_obs(m1)
rm(m1)
model2 <- get_rt_model_ring_obs(m2)
rm(m2)



# convert in order to get D predictions for m2
full_join(
  model1 %>% filter(feature %in% c("orange", "pink", "purple")) %>%
    rename(feature1 = "feature", D1 = "D"),
  model1 %>% filter(feature %in% c("circle", "diamond", "triangle")) %>%
    rename(feature2 = "feature", D2 = "D"),
  by = c(".draw", "observer", "ring", "a", "ndt", "sd")) %>%
  unite(feature, feature1, feature2) %>%
  mutate(D_collinear = 1/((1/D1) + (1/D2)),
         D_best_feature = pmin(D1, D2),
         D_orth_contrast =  1/sqrt(1/(D1^2) + (1/D2^2))) %>%
  select(.draw, observer, ring, feature, D_collinear, D_best_feature, D_orth_contrast) -> Dp

# merge everything
full_join(model2, Dp, 
          by = c(".draw", "observer", "ring", "feature")) %>%
  pivot_longer(c(D, 
                 D_collinear, D_best_feature, D_orth_contrast), 
               names_to = "method", values_to = "b") -> models

rm(Dp)
rm(model1, model2)


```

Now we remove ring 1, purple, pink and the few remaining participants with negative slopes.

```{r}
models %>% 
  filter(
    ring != 1,
    str_detect(feature, "orange"),
    !(observer %in% neg_slopes2$observer)) -> models

d2 %>% 
  filter(
    ring != 1,
    str_detect(feature, "orange"),
    !(observer %in% neg_slopes2$observer)) -> d2

```

Now we make predictions.

```{r}
make_pred <- function(drw) {
  
  draw  <- unique(models$.draw)[drw]
  
  mod <- filter(models, .draw == draw)
  
  full_join(mod, d2, by = c("observer", "ring", "feature"),
            relationship = "many-to-many") %>%
    select(.draw, method, observer, ring, feature, lnd, a, b, ndt, sd, rt) %>%
    mutate(p_mu_rt = exp(ndt) + exp(a + b*lnd),
           loglik = dshifted_lnorm(rt, meanlog = log(p_mu_rt), sdlog = sd, shift = ndt, log = T),
           abs_err = abs(rt-p_mu_rt)) %>%
    arrange(method, observer, ring, feature, lnd)  %>% 
  select(.draw, method, observer, ring, feature, lnd, rt, p_mu_rt, loglik, abs_err)-> dp
  
  return(dp)

}

dp <- map_df(1:ndraws, make_pred)

```


## Absolute error

```{r}

dp %>% 
  filter(lnd > 0) %>%
  group_by(.draw,lnd, ring, method) %>%
  summarise(mean_err = mean(abs_err), .groups = "drop") %>%
  pivot_wider(names_from = "method", values_from = "mean_err") %>%
  pivot_longer(c(D_collinear, D_best_feature, D_orth_contrast), 
               names_to = "method", values_to = "Dp") %>%
  mutate(rel_mean_abs_err = Dp/D) -> Derr

Derr %>% ungroup() %>%
  group_by(ring, method) %>% 
  median_hdci(rel_mean_abs_err, .width = 0.97) %>%
  knitr::kable() %>%
  kable_styling() 

Derr %>% ggplot(aes(lnd, rel_mean_abs_err, fill = method)) +
  stat_lineribbon(alpha = 0.2, .width = 0.97) +
  facet_grid(ring~method) +
  geom_hline(yintercept = 1, linetype = 2) +
  ggthemes::scale_color_ptol() +
    coord_cartesian(ylim = c(0.99, 1.1))

```

The removal of negative slopes does indeed help the collinear contrast model: in particular, the median HDCI does now look much more sensible. However, the orthogonal contrast model still seems to be the best overall model even when applying these strict exclusion criteria.