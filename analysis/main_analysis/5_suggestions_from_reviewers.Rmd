---
title: "Supplementary Materials: SUggestions from Reviewers"
author: "Alasdair D.F. Clarke and Anna E. Hughes"
date: "2023-03-24"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.height = 3,
  fig.align = "center")
```

# Introduction

```{r load-packages, include = FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
library(ggpmisc)
library(ggridges)
library(corrr)
library(knitr)
library(kableExtra)
```

```{r}
# set ggplot2 theme
theme_set(ggthemes::theme_tufte())
colourPalette <- c("#e78429", "#ed968c", "#7c4b73","#aadce0", "#72bcd5", "528fad")

# use parallel cores for mcmc chains!
options(mc.cores = 4)

# reduce the number of decimal places
options(digits = 3)

# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")

# set seed to make sure everything is reproducible 
set.seed(100320021)
```


Here we present two additional analysis that were suggested during the Stage Two peer review process. We thank the reviewers for their suggestions. 

# Effect of block on correlations

In `4_Planned_Explorations` we reported that \ldots. 

During peer review it was suggested that we could partially disentangle contributions of feature type and block from one another by looking at how the correlations change within sub-blocks. <EXPAND>. 

If the correlation results are primarily being driven by block, then we could expect to see a decreases in the correlation over sub-blocks. Whereas if it is down to the difference in colour v shape features.



```{r cache=TRUE, warning = FALSE}
## Import and Remove Outliers 
source("1_pre_process_data.R")

# remove feature = circle, diamond, triangle (these are all expt 1b, which is blocked)
# expt 1b is in a different block for each person so each person will have one block missing at random, but I THINK this will be okay
d1 <- d1 %>% 
  mutate(block = as_factor(block)) %>%
  filter(feature == "pink" | feature == "purple" | feature == "orange")
```

We're going to refit the model (single feature only), this time including block info. 

```{r}

n_chains = 4
n_itr = 5000

# fit_model <- function(d, fam, prior, formula, samp_prior = "no") { 
#   
#   # wrapper function for running models
#   # this way, easier to make sure all models are using the same settings!
#   
#   m <- brm(
#     formula,
#     data = d,
#     family = brmsfamily(fam),
#     prior = prior,
#     chains = n_chains,
#     iter = n_itr,
#     init = my_inits,
#     save_pars = save_pars(all=TRUE),
#     silent = TRUE,
#     backend = 'cmdstanr',
#     control = list(adapt_delta = 0.9),
#     sample_prior = samp_prior)
#   
#   return(m)
# }
# 
# 
# my_f <- brms::bf(rt ~ 0 + block + block:feature:lnd + (0 + block + feature:lnd|observer),
#                  ndt ~ 1 + (1|observer))
# 
# my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))
# 
# my_prior <- c(
#   # prior_string("normal(-0.5, 0.3)", class = "Intercept"),
#   prior_string("normal(0, 0.2)", class = "b"),
#   prior_string("normal(-1, 0.2)", class = "b", coef = "block1"),
#   prior_string("normal(-1, 0.2)", class = "b", coef = "block2"),
#   prior_string("normal(-1, 0.2)", class = "b", coef = "block3"),
#   prior_string("normal(-1, 0.2)", class = "b", coef = "block4"),
#   prior_string("normal(-1, 0.2)", class = "b", coef = "block5"),
#   prior_string("normal(-1, 0.5)", class = "Intercept", dpar = "ndt" ),
#   prior_string("cauchy(0, 0.4)", class = "sigma"),
#   prior_string("cauchy(0, 0.05)", class = "sd"),
#   prior_string("cauchy(0, 0.05)", class = "sd", dpar = "ndt"))
# 
# # now run model for single feature data
# m <- fit_model(d1, "shifted_lognormal", my_prior, my_f)
# saveRDS(m, "exp1_block.model")
rm(m)

# read in model
m <- readRDS("exp1_block.model")

```

Extract slopes per person x feature x block

```{r}
# extract the slopes per person per feature per block
samples <- gather_draws(m, `[rb]_.*`, regex=T, ndraws = 100)

samples_ff <- samples %>%
  filter(str_detect(.variable, "b_")) %>%
  filter(str_detect(.variable, ":lnd")) %>%
  separate(.variable, c("block", "feature", "lnd"),  ":") %>%
  select(-lnd, -.chain, -.iteration) %>%
  mutate(block = str_remove(block, "b_"),
         feature = str_remove(feature, "feature")) %>%
  rename(D = ".value")

samples_rf <- filter(samples, str_detect(.variable, "r_")) %>% 
  select(-.chain, -.iteration) %>% 
  filter(str_detect(.variable, ":lnd")) %>%
  rename(feature = ".variable", rD = ".value") %>%
  separate(feature, into = c("observer", "feature"), ",") %>%
  mutate(observer = parse_number(observer),
         feature = str_remove(feature, "feature"),
         feature = str_remove(feature, ":lnd"),
         feature = str_remove(feature, "]")) %>%
  separate(feature, c("block", "feature"), ":") 

full_join(samples_ff, samples_rf) %>%
      mutate(D = D + rD) %>%
      select(-rD) -> samples
```

## Computer correlation per sample

First we define a little function to calculate correlations within feature from one block to the next:

```{r}

get_cor_matrix <- function(df, key) {
  
  df %>% 
    #pivot_wider(names_from = "block", values_from = "D") %>%
    select(-observer) %>%
    correlate() %>%
    mutate(.draw = key$.draw)-> dout
  
  return(dout)
}
```


Now for each feature x block x sample, compute the correlations

```{r}

samples %>% 
  unite(block_feature, block, feature) %>%
  pivot_wider(names_from = block_feature, values_from = D) %>%
  group_by(.draw) %>%
  group_map(get_cor_matrix) %>%
  bind_rows -> dc
```

And plot to make sense of this madness!

```{r}
dc %>% 
  rename(block_feature1 = "term") %>%
  pivot_longer(-c(.draw, block_feature1), names_to = "block_feature2", values_to = "r") %>%
  separate(block_feature1, into = c("blockA", "featureA")) %>%
  separate(block_feature2, into = c("blockB", "featureB")) %>%
  mutate(blockA = parse_number(blockA),
         blockB = parse_number(blockB)) %>%
  select(.draw, blockA, featureA, blockB, featureB, r) -> dc


dc %>%
  filter(blockA == 1) %>%
  group_by(featureA, featureB, blockB) %>%
  median_hdci(r, .width = c(.53, .97)) %>%
  rename(feature = "featureA") %>%
  ggplot(aes(blockB, ymin = .lower, y = r, ymax = .upper, 
             group = interaction( .width))) + 
  geom_path() + 
  geom_hline(yintercept = 0, linetype = 2) + 
  geom_ribbon(alpha = 0.125) + 
  facet_grid(feature~featureB)  +
  scale_x_continuous("block") +
  scale_y_continuous("correlation (r) with block 1")
```



