---
title: "Supplementary Materials: Planned Explorations"
author: "Alasdair D.F. Clarke and Anna E. Hughes"
date: "2023-03-24"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.height = 3,
  fig.align = "center")
```

# Introduction

```{r load-packages, include = FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
library(ggpmisc)
library(ggridges)
library(corrr)
library(knitr)
library(kableExtra)
```

```{r}
# set ggplot2 theme
theme_set(ggthemes::theme_tufte())
colourPalette <- c("#e78429", "#ed968c", "#7c4b73","#aadce0", "#72bcd5", "528fad")

# use parallel cores for mcmc chains!
options(mc.cores = 4)

# reduce the number of decimal places
options(digits = 3)

# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")

# set seed to make sure everything is reproducible 
set.seed(100320021)
```

# Individual Differences in D

First, we will look to see the extent to which $D$ varies from one person to the next. We will also ask whether these variations are correlated, both for single and for double feature search. 


```{r cache=TRUE, warning = FALSE}
## Import and Remove Outliers 

source("1_pre_process_data.R")

m1 <- readRDS("exp1.model")
m2 <- readRDS("exp2_random.model")

# Calculate slopes, fixed=FALSE means we will return samples per-observer, rather
# than simply the fixed effects. 
samples1 <- get_slopes(m1, fixed = F)
samples2 <- get_slopes(m2, fixed = F) 
```

## Correlations for single feature search

We begin by calculating the correlations for single feature search. The code below plots the left hand side of Figure 2.1, and shows the range of individual differences seen in $D_c$ and $D_s$: it can be seen that there is quite a lot of between-participant variability in this experiment.

```{r create_D_obs_plot, cache=TRUE}
ggplot(samples1, aes(x=D, y= as_factor(feature), 
                     group = interaction(observer, feature), fill = feature)) +
  geom_density_ridges(alpha = 0.5) +
  scale_fill_manual(values = colourPalette) + 
  scale_x_continuous(expression(D[c] ~ and ~ D[s])) + 
  scale_y_discrete("feature") + 
  theme(legend.position = "none") -> plt_D_obs
```

```{r}
 get_slopes(m1, fixed = T) %>%
  group_by(feature) %>%
  summarise(D = mean(D)) -> mean_slopes

max_range_fix <- max(mean_slopes$D) - min(mean_slopes$D)
  
```

The code above allows us to compute the range of the fixed effect (i.e. the shallowest to the steepest fixed effect, which turns out to be the difference between $D_~triangle~$ to $D_~purple~$) and has a value of `r max_range_fix`.

We can also look at the range within a feature, and see that there is also a lot of variability here:

```{r, message = FALSE}
samples1 %>% group_by(feature, observer) %>%
  summarise(D = mean(D)) %>%
  summarise(minD = min(D), 
            maxD = max(D),
            range = maxD - minD) %>%
  knitr::kable()  %>%
  kable_styling() 
```

To investigate individual differences further, we calculated the correlations between each of the features, by calculating Pearson's $r$ for each sample from our posterior, which gives us a full posterior distribution for the correlations.

Here, we define a function for computing the correlation for a sample from our posterior:

```{r}
compute_corr <- function(drw, df) {
  df %>% filter(.draw==drw) %>%
    select(-.draw) %>%
    correlate(quiet = TRUE) %>%
    stretch() -> dout
  
  return(dout)
}
```

We then apply this function to all the samples in our posterior: 

```{r compute_single_feature_corr, cache=TRUE}
samples1 %>% 
  pivot_wider(names_from = "feature", values_from = "D") %>%
  select(-observer) -> dat_for_corr

dcorr <- map_df(unique(dat_for_corr$.draw), compute_corr, dat_for_corr) %>%
  mutate(x = as_factor(x), 
         x = fct_relevel(x, "pink", "purple", "orange"), 
         y = as_factor(y),
         y = fct_relevel(y, "pink", "purple", "orange"))
```

Finally, we use this to create a plot of the correlations between features:

```{r create_single_feat_plot, cache=TRUE}
dcorr %>% group_by(x, y) %>%
  median_hdci(r, .width = 0.97) %>%
  mutate(fill = if_else(.lower>0, "nonezero", "zero")) %>%
  select(x, y, fill) -> dfill

ggplot(left_join(dcorr, dfill, by = c("x", "y")), aes(x, r)) +
  stat_slabinterval(alpha = 0.5, aes(fill = fill), 
                    point_interval = "median_hdci",
                    .width = c(0.53, 0.97), fatten_point = 0) + 
  geom_hline(yintercept = 0, linetype = 2) + 
  facet_wrap(~y) +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1),
        legend.position = "none",
        axis.title.x = element_blank()) +
  scale_y_continuous("Pearson's correlation coefficent", 
                     limits = c(-0.6, 1), expand = c(0, 0), breaks = seq(-0.5, 1, 0.5)) +
  scale_fill_manual(values = c("darkgreen", "black")) -> plt_corr
```

```{r plot-single-feature-corr, fig.cap = "Indiviual differences in Dc and Ds. (left) Posterior probability distributions for Dc and Ds for each individual. (right) Estimated correlations between each of the Dc and Ds.", warning = FALSE, message = FALSE, echo = FALSE}

plt_D_obs + plt_corr

```

```{r, include = FALSE}

ggsave("../../plots/single_feature_correlations.pdf", height = 2.5, width = 7)

rm(plt_D_obs, plt_corr)
```

Figure 2.1 shows that $D_c$ and $D_s$ are correlated within feature classes, but there does not seem to be good evidence of correlation of any of the colour features with any of the shape features.

## Correlations for double feature search 

We can then calculate the same correlations, but this time for the double-feature conditions.

```{r compute_double_feature_corr, cache=TRUE}
######### Now do double feature search
samples2 %>% 
  pivot_wider(names_from = "feature", values_from = "D") %>%
  select(-observer) -> dat_for_corr

dcorr <- map_df(unique(dat_for_corr$.draw), compute_corr, dat_for_corr) %>%
  mutate(x = as_factor(x), 
         y = as_factor(y))
```

```{r plot-cor-double-feature, fig.height=6, fig.cap = "Estimated correlations for double feature search.", warning = FALSE, echo = FALSE}
ggplot(dcorr, aes(x, r)) +
  stat_slabinterval(.width = c(0.53, 0.97)) + 
  geom_hline(yintercept = 0, linetype = 2) + 
  facet_wrap(~y) +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1))

rm(dcorr)
```

Figure 2.2 shows that the correlations between the different double-feature conditions are quite weak, presumably due to range restriction (the search slopes are fairly flat, and therefore the individual differences are smaller).

## Predicting $D$ per person

In the main manuscript, we combine the single feature search slopes to predict the double feature conditions across all participants. Here, we show the predictions for each participant individually in Figure 2.3. We can see some variability, though in most cases, this is across all combination methods e.g. participant 7 is relatively poorly predicted by all methods, whereas participant 2 is relatively well predicted by all methods. In general most participants appear to be best predicted by the orthogonal contrast method, though there are possibly exceptions (e.g. participant 20 may be best predicted by the best feature method, participant 34 may be best predicted by the collinear contrast method).

```{r calc_D, cache=TRUE}
#########
# Look at how well we can predict Dcs per person
calc_D <- function(feature1, feature2, observer) {
  
  obs <- observer
  D1 <- filter(samples1, feature == feature1, observer == obs)$D
  D2 <- filter(samples1, feature == feature2, observer == obs)$D
  
  # now calculate D_overall using the three proposed methods
  D_collinear = 1/((1/D1) + (1/D2))
  D_best_feature = pmin(D1, D2)
  D_orth_contrast =  1/sqrt(1/(D1^2) + (1/D2^2))
  
  return(tibble(.draw = 1:length(unique(samples1$.draw)),
                observer = obs,
                feature = paste(feature1, feature2, sep = "_"),
                feature1 = feature1, feature2 = feature2,
                collinear = D_collinear,
                `best feature` = D_best_feature,
               `orthogonal contrast` = D_orth_contrast,
               ))
}
```

```{r running_calcD, cache=TRUE}
things_to_calc <- samples2 %>% 
  select(-.draw, -D) %>%
  distinct() %>% 
  separate(feature, c("feature1", "feature2")) %>%
  select(feature1, feature2, observer)

slopes <- pmap_df(things_to_calc, calc_D) %>% 
  full_join(samples2, by = c("observer", ".draw", "feature")) %>%
  pivot_longer(c(collinear, `best feature`, `orthogonal contrast`), names_to = "method", values_to = "Dp") %>% 
  group_by(observer, method, feature ) %>%
  summarise(De = median(D), 
            Dp = median(Dp), .groups = "drop")
```

```{r plot-Dp, fig.height = 15, fig.width = 10, fig.cap = "D predictions for each observer.", message = FALSE}
ggplot(slopes, aes(Dp, De, colour = method)) + geom_point() +
  geom_smooth(method = lm, alpha = 0.25) +
  geom_abline(linetype = 2) + 
  facet_wrap(~observer, nrow = 8)
```

```{r comp_corr, cache=TRUE}
comp_corr <- function(obs, meth) {
  df <- filter(slopes, observer == obs, method == meth)
  r <- cor(df$De, df$Dp)

  
  return(r)
}

comp_abs_err <- function(obs, meth) {
  df <- filter(slopes, observer == obs, method == meth)
  abs_err = sum(abs(df$De-df$Dp))
  
  return(abs_err)
}

r_col <- map_dbl(1:40, comp_corr, "collinear")
r_bfe <- map_dbl(1:40, comp_corr, "best feature")
r_oth <- map_dbl(1:40, comp_corr, "orthogonal contrast")

abserr_col <- map_dbl(1:40, comp_abs_err, "collinear")
abserr_bfe <- map_dbl(1:40, comp_abs_err, "best feature")
abserr_oth <- map_dbl(1:40, comp_abs_err, "orthogonal contrast")
```

Figure 2.4 allows us to more systematically look at the correlation coefficient values for each combination method. We can see that across all participants, orthogonal contrast generally has the highest correlation coefficient value, although there are several participants who are very poorly predicted by the orthogonal contrast method (unlike the collinear and the best feature methods).


```{r plot-Dmeth-corr-hist, fig.cap = "Histogram of correlation coefficient values for each combination method.", message = FALSE, warning = FALSE}
tibble(method = rep(c("collinear", "best feature", "orthogonal contrast"), 
                    each=40),
                r = c(r_col, r_bfe, r_oth)) %>%
  ggplot(aes(r, fill = method)) + geom_histogram(alpha = 0.5, position=position_identity())

```

Figure 2.5 is similar to Figure 2.4, but shows the absolute error. Here, there are some outliers for the best feature and collinear contrast methods, with several participants having very high absolute errors using these combination methods.

```{r plot-Dmeth-abserr-hist, fig.cap = "Histogram of absolute error values for each combination method.", message = FALSE, warning = FALSE}


tibble(method = rep(c("collinear", "best feature", "orthogonal contrast"), 
                    each=40),
                abs_err = c(abserr_col, abserr_bfe, abserr_oth)) %>%
  ggplot(aes(abs_err, fill = method)) + geom_histogram(bins = 15, 
                                                       alpha = 0.5, position=position_identity()) + 
  scale_x_continuous("absolute error")

```


```{r, include = FALSE}
#rm(list = ls(all.names = TRUE))
```


# Target eccentricity

We know that there are eccentricity effects in visual search, and so we decided to see whether including a proxy for eccentricity (the 'ring' that the target was in) would improve our model fit.

First, we read in the data again:
 
```{r}
source("1_pre_process_data.R")
```
 

## Model comparison 

We then compare the ring model to a non-ring model (for the training dataset i.e. the single-feature data).

```{r ring_mod_comp}

### first compare ring model to non-ring
m1 <- readRDS("exp1_ring.model")
m0 <- readRDS("exp1.model")

# read in csv and kable
ring_table <- read_csv('model_comp_ring.csv', show_col_types = FALSE)
knitr::kable(ring_table) %>%
  kable_styling() 

```

We can see that the ring model is preferred to the non-ring model - it offers a better model of the data.

```{r include = FALSE}

rm(m0)

```

We can then ask: Does the ring the target is in interact with the distractor type? Figure 3.1 shows the posterior predictions for the ring model, and shows that there does seem to be an interaction: some features have very different values for each ring (e.g. triangle) whereas others are much more similar (e.g. pink/purple).

```{r plot-ring-model, cache=TRUE, fig.cap = "Posterior predictions for the ring model."}

m1 %>% gather_draws(`b_.*`, regex=T) %>%
  select(-.chain, -.iteration) %>% 
  filter(!str_detect(.variable, "ndt")) %>%
  mutate(.variable = str_remove(.variable, "b_"),
         lin_mod_comp = if_else(str_detect(.variable, ":"), "slope", "intercept"),
         ring = as_factor(parse_number(.variable))) -> post

post %>% filter(lin_mod_comp == "slope") %>%
  mutate(feature = str_extract(.variable, "orange|pink|purple|diamond|circle|triangle")) %>%
  ungroup() %>%
  select(-.variable, -lin_mod_comp) -> slopes
  
slopes %>% ggplot(aes(.value, fill = ring)) + geom_density(alpha = 0.5) +
  facet_wrap(~feature) +
  ggthemes::scale_fill_ptol()

```


``` {r plot-ring-model-2, fig.cap = "Fixed effects for predicting the effect of ring, feature and number of distractors on response times."}

d1 %>% modelr::data_grid(feature, ring, lnd = seq(0, 3.5, 0.1)) %>%
  add_epred_draws(m1, ndraws = 1000, re_formula = NA) -> pred

pred %>% group_by(feature, ring, lnd) %>%
  median_hdci(.epred, .width = c(0.53, 0.97)) -> pred2

ggplot(pred2, aes(x = lnd, ymin = .lower, ymax = .upper, fill = ring, group = interaction(ring, .width))) +
  geom_ribbon(alpha = 0.5) + 
  facet_wrap(~feature) +
  scale_fill_manual(values = colourPalette) +
  xlab("Log number of distractors") +
  ylab("Predicted response time (sec)")

```

``` {r include = FALSE}

ggsave("../../plots/ring_single_feature.pdf", width = 7, height = 3)

```

Figure 3.2 shows how these fixed effects also depend on the log number of distractors.

As might be expected, the answer seems to be yes, the effect of eccentricity does seem to depend on the exact distractor type - in particular, the slopes seem to be steeper for the distractors more similar in shape to the target for the furthest eccentricity. Conversely, in some displays (e.g. where the colour is more different) there seems to be little effect of eccentricity.

## Predicting D

We now use the single-feature model (with the ring feature included) to predict D in the double-feature model, in the same way as we did for Hypothesis 3 in the registered analysis.

```{r cache=TRUE}
# now read in m2 so that we can compute Dp
m2 <- readRDS("exp2_ring.model")

# get slopes!
samples1 <- get_slopes(m1, rings = TRUE)
samples2 <- get_slopes(m2, num_features = 2, rings = TRUE)  
```

```{r}
calc_D <- function(ring, feature1, feature2) {
  
  rn = ring
  D1 <- filter(samples1, ring == rn, feature == feature1)$D
  D2 <- filter(samples1, ring == rn, feature == feature2)$D
  
  # now calculate D_overall using the three proposed methods
  D_collinear = 1/((1/D1) + (1/D2))
  D_best_feature = pmin(D1, D2)
  D_orth_contrast =  1/sqrt(1/(D1^2) + (1/D2^2))
  
  return(tibble(.draw = 1:length(unique(samples1$.draw)),
                ring = ring,
               # feature = paste(feature1, feature2, sep = "_"),
                feature1 = feature1, 
               feature2 = feature2,
                collinear = D_collinear,
                `best feature` = D_best_feature,
                `orthogonal contrast` = D_orth_contrast))
}

```

```{r calc-D-run, cache=TRUE, message = FALSE, fig.cap = "The relationship between predicted D and empirical D for the three methods, shown for each ring separately."}

things_to_calc <- samples2 %>% select( -D, -.draw) %>% 
   distinct()

slopes <- pmap_df(things_to_calc, calc_D) %>% 
  full_join(samples2, 
            by = c(".draw", "feature1", "feature2", "ring")) %>% 
  pivot_longer(c(collinear, `best feature`, `orthogonal contrast`), names_to = "method", values_to = "Dp") %>% 
  pivot_longer(c(D, Dp), names_to = "type", values_to = "D") %>% 
  group_by(feature1, feature2, ring,  method, type) 

slopes %>% 
  median_hdci(D) %>%
  unite(D, D, .lower, .upper) %>% 
  select(-.width, -.point, -.interval) %>% 
  pivot_wider(names_from = "type", values_from = "D") %>% 
  separate(D, into = c("De", "De_min", "De_max"), sep = "_", convert = TRUE) %>% 
  separate(Dp, into = c("Dp", "Dp_min", "Dp_max"), sep = "_", convert=  TRUE) %>%
  filter(is.finite(ring)) %>% 
  ggplot(aes(x = Dp, xmin = Dp_min, xmax = Dp_max, y = De, ymin = De_min, ymax = De_max, colour = as_factor(ring))) + 
  geom_point() + 
  geom_errorbar(alpha = 0.5) + 
  geom_errorbarh(alpha = 0.5) + 
  geom_abline(linetype = 2) + 
  geom_smooth(method = "lm", fullrange  = T) +
  # stat_poly_eq(formula = y ~ x, 
  #              aes(label = paste(..eq.label.., ..rr.label.., sep = "*plain(\",\")~")), 
  #              parse = TRUE, size = 2.8, label.y = 0.9, coef.digits = 3, rr.digits = 4, colour="blue") + 
  facet_wrap(~method, scales = "free") +
  ggthemes::scale_color_ptol("target ring") -> target_ring_D_pred

target_ring_D_pred

```

Figure 3.3 shows the relationship between the predicted $D$ and the empirical $D$, and shows that including ring into the model doesn't drastically change the results - orthogonal contrast still seems to be overall the best combination method. Interestingly, the outer rings generally seem to be predicted better than the inner rings.

``` {r include = FALSE}

#ggsave("../../plots/target_ring_D_pred.pdf",  width = 8, height = 3)

```

The table below calculates the absolute errors, again confirming the conclusion that the orthogonal contrast model has the lowest absolute errors.


```{r}

# compute prediction error per feature per ring

slopes  %>% 
  ungroup() %>% 
  pivot_wider(names_from = "type", values_from = "D") %>% 
  mutate(abs_err = abs(D-Dp)) %>% 
  group_by(ring, feature1, feature2, method) %>% 
  summarise(mean_abs_err = mean(abs_err), .groups = "drop") %>% 
  pivot_wider(names_from = "method", values_from = "mean_abs_err") %>% 
  ungroup() -> slopes_err 


add_row(slopes_err, ring = 0, feature1 = "mean", feature2 = "over all", 
        `best feature` = mean(slopes_err[4][[1]]), 
        collinear = mean(slopes_err[5][[1]]), 
        `orthogonal contrast` = mean(slopes_err[6][[1]])) %>% 
  knitr::kable() %>%
  kable_styling() %>%
  row_spec(28,bold=T,hline_after = T)


```

```{r}
## compute regression slopes for Dp to De, ignoring ring and feature
slopes %>% pivot_wider(names_from = "type", values_from = "D") -> Dlm

summary(lm(data = Dlm, D ~ 0 + Dp:method))

```

## Tidy up

```{r}
rm(post, pred, ring_table, samples1, samples2, slopes, things_to_calc)
```



# Predicting Reaction Times

Finally, we use the ring model to predict reaction times (similar to the modified version of hypothesis 4 in the registered analysis).

First, read in data and models again:

```{r}
source("../scripts/pred_rt_functions.R")
source("1_pre_process_data.R")

d1 %>% mutate(observer = as.numeric(observer)) %>%
  select(-nd) -> d1

d2 %>% mutate(observer = as.numeric(observer)) %>%
  select(-nd) -> d2

d2 %>% unite(feature, feature1, feature2) -> d2

m1 <- readRDS("exp1_ring.model") 

m2 <- readRDS("exp2_ring.model") 
```

We then merge the models i.e. adding the $D_p$ values to the double-feature model, and thwn use these to make predictions.

```{r get_rt_models, cache=TRUE}
ndraws <- 100

model1 <- get_rt_model_ring_obs(m1)
rm(m1)
model2 <- get_rt_model_ring_obs(m2)
rm(m2)

# convert in order to get D predictions for m2
full_join(
  model1 %>% filter(feature %in% c("orange", "pink", "purple")) %>%
    rename(feature1 = "feature", D1 = "D"),
  model1 %>% filter(feature %in% c("circle", "diamond", "triangle")) %>%
    rename(feature2 = "feature", D2 = "D"),
  by = c(".draw", "observer", "ring", "a", "ndt", "sd")) %>%
  unite(feature, feature1, feature2) %>%
  mutate(D_collinear = 1/((1/D1) + (1/D2)),
         D_best_feature = pmin(D1, D2),
         D_orth_contrast =  1/sqrt(1/(D1^2) + (1/D2^2))) %>%
  select(.draw, observer, ring, feature, D_collinear, D_best_feature, D_orth_contrast) -> Dp

# merge everything
full_join(model2, Dp, 
          by = c(".draw", "observer", "ring", "feature")) %>%
  pivot_longer(c(D, 
                 D_collinear, D_best_feature, D_orth_contrast), 
               names_to = "method", values_to = "b") -> models

rm(Dp)
rm(model1, model2)

make_pred <- function(drw) {
  
  draw  <- unique(models$.draw)[drw]
  
  mod <- filter(models, .draw == draw)
  
  full_join(mod, d2, by = c("observer", "ring", "feature")) %>%
    select(.draw, method, observer, ring, feature, lnd, a, b, ndt, sd, rt) %>%
    mutate(p_mu_rt = exp(ndt) + exp(a + b*lnd),
           loglik = dshifted_lnorm(rt, meanlog = log(p_mu_rt), sdlog = sd, shift = ndt, log = T),
           abs_err = abs(rt-p_mu_rt)) %>%
    arrange(method, observer, ring, feature, lnd)  %>% 
  select(.draw, method, observer, ring, feature, lnd, rt, p_mu_rt, loglik, abs_err)-> dp
  
  return(dp)

}

dp <- map_df(1:ndraws, make_pred)
```

### Absolute Error

Finally, we calculate the absolute error. A value of 1 means that our estimates of $D$ derived from the single-feature trials does an equally good job at predicting the double-feature trials as using the $D$ fit to the data.

Figure 4.1 shows that (similar to the registered analysis) the accuracy of all three models is good - and the inclusion of the ring factor means that the accuracy stays quite constant across the range of distractor numbers. However, the collinear contrast model has a very wide HDCI, probably because of the mathematical formulation of the model (see the main text of the paper for more discussion of this).

```{r, fig.cap = "Comparing which model does the best job of predicting reaction times: log number of distractors plotted againt the absolute error of the model."}

dp %>% 
  filter(lnd > 0) %>%
  group_by(.draw,lnd, method) %>%
  summarise(mean_err = mean(abs_err), .groups = "drop") %>%
  pivot_wider(names_from = "method", values_from = "mean_err") %>%
  pivot_longer(c(D_collinear, D_best_feature, D_orth_contrast), 
               names_to = "method", values_to = "Dp") %>%
  mutate(rel_mean_abs_err = Dp/D) -> Derr

Derr %>% ungroup() %>%
  group_by(method) %>% 
  median_hdci(rel_mean_abs_err, .width = 0.97) %>%
  knitr::kable() %>%
  kable_styling() 

Derr %>% ggplot(aes(lnd, rel_mean_abs_err, fill = method)) +
  stat_lineribbon(alpha = 0.2, .width = 0.97) +
  facet_grid(.~method) +
  geom_hline(yintercept = 1, linetype = 2) +
  ggthemes::scale_color_ptol() +
    coord_cartesian(ylim = c(0.99, 1.1))

```
